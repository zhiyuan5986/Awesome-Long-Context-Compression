# Awesome Long Context Compression

RECOMP: Improving Retrieval-Augmented LMs with Context Compression and Selective Augmentation, ICLR 2024. [[paper]](https://openreview.net/forum?id=mlJLVigNHp)[[code]](https://github.com/carriex/recomp)

LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression, ACL 2024 and ICLR ME-FoMo 2024.[[paper]](https://aclanthology.org/2024.acl-long.91/)[[code]](https://github.com/microsoft/LLMLingua)

Characterizing Prompt Compression Methods for Long Context Inference, ICML 2024. [[paper]](https://icml.cc/virtual/2024/39599)

In-context Autoencoder for Context Compression in a Large Language Model, ICLR 2024. [[paper]](https://openreview.net/forum?id=uREj4ZuGJE)[[code]](https://github.com/getao/icae)